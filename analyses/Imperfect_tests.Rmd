---
title: "Imperfect tests"
author: "Rachael Caelie (Rocky) Aikens"
date: "11/4/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, fig.align = "center", fig.height = 3, cache = TRUE)
library(confirmationBias)
library(tidyverse)
library(ggpubr)
library(knitr)
library(binom)
library(formattable)
library(RColorBrewer)
library(grid)

set.seed(126)

theme_set(theme_light())

inline_hook <- function(x) {
  if (is.numeric(x)) {
    format(x, scientific = F, digits = 2)
  } else x
}
knitr::knit_hooks$set(inline = inline_hook)

blankplot <- ggplot() + theme_void()

cases_color <- "#715D84"
controls_color <- "#66C2A5"
controls_text_color <- "#488b76"
undiagnosed_color <- "#6A9C99" 
x0_color <- "#E41A1C" # Red
x1_color <- "#377EB8" # Blue

x.labs = c("FALSE" = "X = 0", "TRUE" = "X = 1")

N <- 100000
```

Here we consider a situation in which the diagnostic evaluation itself has some error rate.  Suppose the test has a  sensitivity and specificity of 80%, and the performance of the test itself does not depend on X or R.

## Case 2A with imperfect tests

```{r}
df <- generate_cs_beta(n = N, prevalence = 0.1)
```

```{r}
df_tested <- test_cross_sectional(df, theta = c(-13, 20, 3), sensitivity = 0.8, specificity = 0.8)
```

For simplicity, I'll start with case 2A.  The figure below shows the actual and observed incidences.  The turquoise colored portion of the "Observed" bars represents the proportion of observed disease cases which are actually false positives.  Because the $X = 1$ population is tested more, they have the greater burden of false positives _and_ false negatives.  However, because the $X = 0$ population is only tested for more representative cases, a greater proportion of their tests are positive overall.

```{r fig.height=3, fig.width=3}
df_x1 <- filter(df_tested, x == 1)
df_x0 <- filter(df_tested, x == 0)

plt_data_under <- rbind(binom.confint(sum(df_x1$diagnose), dim(df_x1)[1], method = "asymptotic"), 
      binom.confint(sum(df_x0$diagnose), dim(df_x0)[1], method = "asymptotic"),
      binom.confint(sum(df_x1$disease), dim(df_x1)[1], method = "asymptotic"),
      binom.confint(sum(df_x0$disease), dim(df_x0)[1], method = "asymptotic")) %>%
  rename(diagnosed = x, Incidence = mean) %>%
  mutate(x = as.factor(c(1, 0, 1, 0)),
        status = c("Observed", "Observed", "Actual", "Actual")) 

plt_data_under[3:4,5:6] <- NA

plt_data_over <- plt_data_under

plt_data_over[1:2, 4] <- df_tested %>%
  group_by(x) %>%
  mutate(TP = diagnosed & disease) %>%
  summarize(Incidence = mean(TP)) %>%
  arrange(desc(x)) %>%
  pull(Incidence)

plt_data_under[3:4, 4] <- 0

a <- ggplot(plt_data_under, aes(x = status, y = Incidence, fill = x, group = x, alpha = status)) +
  geom_col(position = position_dodge(width = 1), fill = controls_color) +
  geom_col(data = plt_data_over, aes(x = status, y = Incidence, fill = x, group = x, alpha = status), position = position_dodge(width = 1)) +
  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.25, position = position_dodge(width = 1)) +
  labs(title = "Disease incidence") +
  xlab("")+
  scale_alpha_manual(values = c(0.5, 1), guide = "none") + 
  scale_fill_brewer(palette = "Set1", guide = "none") +
  ylim(c(0,0.175))

a

df_tested %>%
  group_by(x) %>%
  mutate(TP = diagnosed & disease, FP = diagnosed & !disease, FN = tested & disease & !diagnosed) %>%
  summarize("Tests" = sum(tested), "True Positives" = sum(TP), "False Positives" = sum(FP), "False Negatives" = sum(FN), "Positive test rate" = sum(TP + FP)/sum(tested)) %>%
  kable()
```

Here are examples of a few runs of the simulation with different sensitivity and specificity levels.  In particular, it seems that a low sensitivity test impacts both groups equally in this set-up, but a low specificity test results in a proportionally larger share of false positives for the more-tested group.  Thus, the lower specificity testing scenarios also lead to a greater difference in the observed incidence rates between groups.

```{r se1sp1}
df_tested <- test_cross_sectional(df, theta = c(-13, 20, 3))
df_x1 <- filter(df_tested, x == 1)
df_x0 <- filter(df_tested, x == 0)

plt_data_under <- rbind(binom.confint(sum(df_x1$diagnose), dim(df_x1)[1], method = "asymptotic"), 
      binom.confint(sum(df_x0$diagnose), dim(df_x0)[1], method = "asymptotic"),
      binom.confint(sum(df_x1$disease), dim(df_x1)[1], method = "asymptotic"),
      binom.confint(sum(df_x0$disease), dim(df_x0)[1], method = "asymptotic")) %>%
  rename(diagnosed = x, Incidence = mean) %>%
  mutate(x = as.factor(c(1, 0, 1, 0)),
        status = c("Observed", "Observed", "Actual", "Actual")) 

incidence_ratio <- plt_data_under[1, 4]/plt_data_under[2, 4]
grob <- grobTree(textGrob(paste("Observed incidence ratio:", round(incidence_ratio, 1)),
                          x=0.1,  y=0.9, hjust=0,
  gp=gpar(col="red", fontsize=13, fontface="italic")))

plt_data_under[3:4,5:6] <- NA

plt_data_over <- plt_data_under

plt_data_over[1:2, 4] <- df_tested %>%
  group_by(x) %>%
  mutate(TP = diagnosed & disease) %>%
  summarize(Incidence = mean(TP)) %>%
  arrange(desc(x)) %>%
  pull(Incidence)

plt_data_under[3:4, 4] <- 0

sen_1_spe_1 <- ggplot(plt_data_under, aes(x = status, y = Incidence, fill = x, group = x, alpha = status)) +
  geom_col(position = position_dodge(width = 1), fill = controls_color) +
  geom_col(data = plt_data_over, aes(x = status, y = Incidence, fill = x, group = x, alpha = status), position = position_dodge(width = 1)) +
  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.25, position = position_dodge(width = 1)) +
  labs(title = "Sensitivity = 1, Specificity = 1") +
  xlab("")+
  annotation_custom(grob) +
  scale_alpha_manual(values = c(0.5, 1), guide = "none") + 
  scale_fill_brewer(palette = "Set1", guide = "none") +
  ylim(c(0,0.175))
```

```{r se1sp0.7}
df_tested <- test_cross_sectional(df, theta = c(-13, 20, 3), sensitivity = 1, specificity = 0.7)
df_x1 <- filter(df_tested, x == 1)
df_x0 <- filter(df_tested, x == 0)

plt_data_under <- rbind(binom.confint(sum(df_x1$diagnose), dim(df_x1)[1], method = "asymptotic"), 
      binom.confint(sum(df_x0$diagnose), dim(df_x0)[1], method = "asymptotic"),
      binom.confint(sum(df_x1$disease), dim(df_x1)[1], method = "asymptotic"),
      binom.confint(sum(df_x0$disease), dim(df_x0)[1], method = "asymptotic")) %>%
  rename(diagnosed = x, Incidence = mean) %>%
  mutate(x = as.factor(c(1, 0, 1, 0)),
        status = c("Observed", "Observed", "Actual", "Actual")) 

incidence_ratio <- plt_data_under[1, 4]/plt_data_under[2, 4]
grob <- grobTree(textGrob(paste("Observed incidence ratio:", round(incidence_ratio, 1)),
                          x=0.1,  y=0.9, hjust=0,
  gp=gpar(col="red", fontsize=13, fontface="italic")))

plt_data_under[3:4,5:6] <- NA

plt_data_over <- plt_data_under

plt_data_over[1:2, 4] <- df_tested %>%
  group_by(x) %>%
  mutate(TP = diagnosed & disease) %>%
  summarize(Incidence = mean(TP)) %>%
  arrange(desc(x)) %>%
  pull(Incidence)

plt_data_under[3:4, 4] <- 0

sen_1_spe_07 <- ggplot(plt_data_under, aes(x = status, y = Incidence, fill = x, group = x, alpha = status)) +
  geom_col(position = position_dodge(width = 1), fill = controls_color) +
  geom_col(data = plt_data_over, aes(x = status, y = Incidence, fill = x, group = x, alpha = status), position = position_dodge(width = 1)) +
  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.25, position = position_dodge(width = 1)) +
  labs(title = "Sensitivity = 1, Specificity = 0.7") +
  xlab("")+
  annotation_custom(grob) +
  scale_alpha_manual(values = c(0.5, 1), guide = "none") + 
  scale_fill_brewer(palette = "Set1", guide = "none") +
  ylim(c(0,0.175))
```

```{r se0.7sp1}
df_tested <- test_cross_sectional(df, theta = c(-13, 20, 3), sensitivity = 0.7, specificity = 1)
df_x1 <- filter(df_tested, x == 1)
df_x0 <- filter(df_tested, x == 0)

plt_data_under <- rbind(binom.confint(sum(df_x1$diagnose), dim(df_x1)[1], method = "asymptotic"), 
      binom.confint(sum(df_x0$diagnose), dim(df_x0)[1], method = "asymptotic"),
      binom.confint(sum(df_x1$disease), dim(df_x1)[1], method = "asymptotic"),
      binom.confint(sum(df_x0$disease), dim(df_x0)[1], method = "asymptotic")) %>%
  rename(diagnosed = x, Incidence = mean) %>%
  mutate(x = as.factor(c(1, 0, 1, 0)),
        status = c("Observed", "Observed", "Actual", "Actual")) 

incidence_ratio <- plt_data_under[1, 4]/plt_data_under[2, 4]
grob <- grobTree(textGrob(paste("Observed incidence ratio:", round(incidence_ratio, 1)),
                          x=0.1,  y=0.9, hjust=0,
  gp=gpar(col="red", fontsize=13, fontface="italic")))

plt_data_under[3:4,5:6] <- NA

plt_data_over <- plt_data_under

plt_data_over[1:2, 4] <- df_tested %>%
  group_by(x) %>%
  mutate(TP = diagnosed & disease) %>%
  summarize(Incidence = mean(TP)) %>%
  arrange(desc(x)) %>%
  pull(Incidence)

plt_data_under[3:4, 4] <- 0

sen_07_spe_1 <- ggplot(plt_data_under, aes(x = status, y = Incidence, fill = x, group = x, alpha = status)) +
  geom_col(position = position_dodge(width = 1), fill = controls_color) +
  geom_col(data = plt_data_over, aes(x = status, y = Incidence, fill = x, group = x, alpha = status), position = position_dodge(width = 1)) +
  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.25, position = position_dodge(width = 1)) +
  labs(title = "Sensitivity = 0.7, Specificity = 1") +
  xlab("")+
  annotation_custom(grob) +
  scale_alpha_manual(values = c(0.5, 1), guide = "none") + 
  scale_fill_brewer(palette = "Set1", guide = "none") +
  ylim(c(0,0.175))
```

```{r se0.7sp0.7}
df_tested <- test_cross_sectional(df, theta = c(-13, 20, 3), sensitivity = 0.7, specificity = 0.7)
df_x1 <- filter(df_tested, x == 1)
df_x0 <- filter(df_tested, x == 0)

plt_data_under <- rbind(binom.confint(sum(df_x1$diagnose), dim(df_x1)[1], method = "asymptotic"), 
      binom.confint(sum(df_x0$diagnose), dim(df_x0)[1], method = "asymptotic"),
      binom.confint(sum(df_x1$disease), dim(df_x1)[1], method = "asymptotic"),
      binom.confint(sum(df_x0$disease), dim(df_x0)[1], method = "asymptotic")) %>%
  rename(diagnosed = x, Incidence = mean) %>%
  mutate(x = as.factor(c(1, 0, 1, 0)),
        status = c("Observed", "Observed", "Actual", "Actual")) 

incidence_ratio <- plt_data_under[1, 4]/plt_data_under[2, 4]
grob <- grobTree(textGrob(paste("Observed incidence ratio:", round(incidence_ratio, 1)),
                          x=0.1,  y=0.9, hjust=0,
  gp=gpar(col="red", fontsize=13, fontface="italic")))

plt_data_under[3:4,5:6] <- NA

plt_data_over <- plt_data_under

plt_data_over[1:2, 4] <- df_tested %>%
  group_by(x) %>%
  mutate(TP = diagnosed & disease) %>%
  summarize(Incidence = mean(TP)) %>%
  arrange(desc(x)) %>%
  pull(Incidence)

plt_data_under[3:4, 4] <- 0

sen_07_spe_07 <- ggplot(plt_data_under, aes(x = status, y = Incidence, fill = x, group = x, alpha = status)) +
  geom_col(position = position_dodge(width = 1), fill = controls_color) +
  geom_col(data = plt_data_over, aes(x = status, y = Incidence, fill = x, group = x, alpha = status), position = position_dodge(width = 1)) +
  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.25, position = position_dodge(width = 1)) +
  labs(title = "Sensitivity = 0.7, Specificity = 0.7") +
  xlab("")+
  annotation_custom(grob) +
  scale_alpha_manual(values = c(0.5, 1), guide = "none") + 
  scale_fill_brewer(palette = "Set1", guide = "none") +
  ylim(c(0,0.175))
```

```{r fig.height = 6, fig.width=8}
ggarrange(sen_1_spe_1, sen_1_spe_07, sen_07_spe_1, sen_07_spe_07, ncol = 2, nrow = 2)
```

Here are the results over 1,000 simulations of case 2A in each of the four scenarios above.

```{r}
run_case2A <- function(se = 1, sp = 1){

  df <- generate_cs_beta(n = N, prevalence = 0.1)

  df_tested <- test_cross_sectional(df, theta = c(-13, 20, 3), sensitivity = se, specificity = sp)

  df_tested %>% group_by(x) %>%
      mutate(x = ifelse(x, "X1", "X0")) %>%
      summarize(percent_cases_diagnosed = sum(diagnosed & disease)/sum(disease), est_incidence = sum(diagnosed)/n(), .groups = "drop") %>%
      pivot_wider(names_from = x, values_from = c(percent_cases_diagnosed, est_incidence)) %>%
      mutate(est_relative_incidence = est_incidence_X1/est_incidence_X0) 
}
```

```{r}
# Run small simulation study
result_2A_se1_sp1 <- do.call("rbind", replicate(n = 1000, run_case2A(se = 1, sp = 1), simplify = FALSE))
result_2A_se1_sp07 <- do.call("rbind", replicate(n = 1000, run_case2A(se = 1, sp = 0.7), simplify = FALSE))
result_2A_se07_sp1 <- do.call("rbind", replicate(n = 1000, run_case2A(se = 0.7, sp = 1), simplify = FALSE))
result_2A_se07_sp07 <- do.call("rbind", replicate(n = 1000, run_case2A(se = 0.7, sp = 0.7), simplify = FALSE))
```
```{r}
means2A_se1_sp1 <- result_2A_se1_sp1 %>% summarize_all(mean)
means2A_se1_sp07 <- result_2A_se1_sp07 %>% summarize_all(mean)
means2A_se07_sp1 <- result_2A_se07_sp1 %>% summarize_all(mean)
means2A_se07_sp07 <- result_2A_se07_sp07 %>% summarize_all(mean)

rbind(means2A_se1_sp1, means2A_se1_sp07, means2A_se07_sp1, means2A_se07_sp07) %>%
  `colnames<-`(c("% cases diagnosed (X = 0)", "% cases diagnosed (X = 1)", "est. incidence (X = 0)", "est. incidence (X = 1)", "est. relative incidence")) %>%
  mutate(scenario = c("Perfect test", "Poor specificity", "Poor sensitivity", "Poor sensitivity and specificity")) %>%
  kable(digits = 3)
```

```{r}
sd2A_se1_sp1 <- result_2A_se1_sp1 %>% summarize_all(sd)
sd2A_se1_sp07 <- result_2A_se1_sp07 %>% summarize_all(sd)
sd2A_se07_sp1 <- result_2A_se07_sp1 %>% summarize_all(sd)
sd2A_se07_sp07 <- result_2A_se07_sp07 %>% summarize_all(sd)

rbind(sd2A_se1_sp1, sd2A_se1_sp07, sd2A_se07_sp1, sd2A_se07_sp07) %>%  
  `colnames<-`(c("SD % cases diagnosed (X = 0)", "SD % cases diagnosed (X = 1)", "SD est. incidence (X = 0)", "est. incidence (X = 1)", "SD est. relative incidence")) %>%
  mutate(scenario = c("Perfect test", "Poor specificity", "Poor sensitivity", "Poor sensitivity and specificity")) %>%
  kable(digits = 3)
```


### The distribution of representativeness

What does an imperfect test mean for the observed distribution of representativeness?  False positives (turquoise) contribute to the observed distribution of representativeness even though they are not true disease cases.  These false-positive individuals tend to fall lower on the distribution of representativeness than the true-positive individuals.  In other words, they "fatten" the left tail of the observed distribution of representativeness, but this effect is more pronounced for the more-tested group ($X = 1$).

```{r fig.height=3, fig.width=8}
x.labs = c("FALSE" = "X = 0", "TRUE" = "X = 1")

diseased <- df_tested %>% filter(disease == TRUE) %>%
  mutate(group = "Individuals with Disease", alpha = 0.7, status = x)

diagnosed <- df_tested %>% filter(diagnosed == TRUE) %>%
  mutate(group = "Individuals Diagnosed", alpha = 1) %>%
  mutate(status = as.factor(ifelse(!disease, 2, x)))

b <- ggplot(data = rbind(diseased, diagnosed), aes(x = representativeness, fill = status, group = status)) +
  geom_histogram(data = diseased, alpha = 0.5, aes(x = representativeness, fill = status, group = status)) +
  geom_histogram(data = diagnosed, aes(x = representativeness, fill = status, group = status)) +
  labs(title = "Distribution of representativeness", x = "Representativeness", y = "Number of individuals") +
  scale_fill_manual(values = c(x0_color, x1_color, controls_color, x0_color, x1_color), drop = F) +
  facet_wrap(~ x, labeller = labeller(x = x.labs)) +
  theme(strip.text.x = element_text(size = 12, face = "bold"), panel.spacing = unit(1, "lines"))

ggarrange(a, b, ncol = 2, widths =c(2,3), legend = F, labels = "AUTO")
```

What about false negatives? The plot below adds false negatives in black.  Since the sensitivity of the test does not depend on representativeness, the distribution of false negatives appears to mirror the distribution of true positives.

```{r fig.height=3, fig.width=8}
x.labs = c("FALSE" = "X = 0", "TRUE" = "X = 1")

diseased <- df_tested %>% filter(disease == TRUE) %>%
  mutate(group = "Individuals with Disease", alpha = 0.7, status = x)

diagnosed <- df_tested %>% filter(diagnosed == TRUE) %>%
  mutate(group = "Individuals Diagnosed", alpha = 1) %>%
  mutate(status = as.factor(ifelse(!disease, 2, x)))

b <- ggplot(data = rbind(diseased, diagnosed), aes(x = representativeness, fill = status, group = status)) +
  geom_histogram(data = diseased, alpha = 0.5, aes(x = representativeness, fill = status, group = status)) +
  geom_histogram(data = diagnosed, aes(x = representativeness, fill = status, group = status)) +
  geom_histogram(data = filter(diseased, tested & !diagnosed), fill = "black") +
  labs(title = "Distribution of representativeness", x = "Representativeness", y = "Number of individuals") +
  scale_fill_manual(values = c(x0_color, x1_color, controls_color, x0_color, x1_color), drop = F) +
  facet_wrap(~ x, labeller = labeller(x = x.labs)) +
  theme(strip.text.x = element_text(size = 12, face = "bold"), panel.spacing = unit(1, "lines"))

ggarrange(a, b, ncol = 2, widths =c(2,3), legend = F, labels = "AUTO")
```

\pagebreak

## Case 2B with imperfect tests

For completenes, here's the same set of simulations and visualizations for case 2B.  These can be harder to interprent because the base rates of disease are not at parity between groups.

```{r get theta_start}
df <- generate_cs_beta(prevalence = c(0.075, 0.15), n = N)

good_model <- glm(disease ~ representativeness + x, data = df, family = binomial())

theta_start <- coef(good_model)
```

```{r}
df <- generate_cs_beta(prevalence = c(0.075, 0.15), n = N)
```

```{r}
df_tested <- test_cross_sectional(df, theta = theta_start, sensitivity = 0.8, specificity = 0.8)
```

The figure below shows the actual and observed incidences in this scenario. Because the $X = 1$ population is tested more, they have the greater raw numbers of false positives _and_ false negatives.  However, it's not clear to me if the relative abundances of false positives and false negatives are somehow "proportional" to the underlying rates of disease. In this case, the positive tests rates are closer to parity between groups (I'm not sure whether the difference is systematic or due to chance).  Maybe this is because the $X = 0$ group has a higher underlying disease risk than the $X = 1$ group.

```{r fig.height=3, fig.width=3}
df_x1 <- filter(df_tested, x == 1)
df_x0 <- filter(df_tested, x == 0)

plt_data_under <- rbind(binom.confint(sum(df_x1$diagnose), dim(df_x1)[1], method = "asymptotic"), 
      binom.confint(sum(df_x0$diagnose), dim(df_x0)[1], method = "asymptotic"),
      binom.confint(sum(df_x1$disease), dim(df_x1)[1], method = "asymptotic"),
      binom.confint(sum(df_x0$disease), dim(df_x0)[1], method = "asymptotic")) %>%
  rename(diagnosed = x, Incidence = mean) %>%
  mutate(x = as.factor(c(1, 0, 1, 0)),
        status = c("Observed", "Observed", "Actual", "Actual")) 

plt_data_under[3:4,5:6] <- NA

plt_data_over <- plt_data_under

plt_data_over[1:2, 4] <- df_tested %>%
  group_by(x) %>%
  mutate(TP = diagnosed & disease) %>%
  summarize(Incidence = mean(TP)) %>%
  arrange(desc(x)) %>%
  pull(Incidence)

plt_data_under[3:4, 4] <- 0

a <- ggplot(plt_data_under, aes(x = status, y = Incidence, fill = x, group = x, alpha = status)) +
  geom_col(position = position_dodge(width = 1), fill = controls_color) +
  geom_col(data = plt_data_over, aes(x = status, y = Incidence, fill = x, group = x, alpha = status), position = position_dodge(width = 1)) +
  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.25, position = position_dodge(width = 1)) +
  labs(title = "Disease incidence") +
  xlab("")+
  scale_alpha_manual(values = c(0.5, 1), guide = "none") + 
  scale_fill_brewer(palette = "Set1", guide = "none") +
  ylim(c(0,0.175))

a

df_tested %>%
  group_by(x) %>%
  mutate(TP = diagnosed & disease, FP = diagnosed & !disease, FN = tested & disease & !diagnosed) %>%
  summarize("Tests" = sum(tested), "True Positives" = sum(TP), "False Positives" = sum(FP), "False Negatives" = sum(FN), "Positive test rate" = sum(TP + FP)/sum(tested)) %>%
  kable()
```

Here are examples of a few runs of the simulation with different sensitivity and specificity levels. It's harder to parse the relative contributions of sensitivity and specificity in this context.  Since the apparent differences are small, it's less obvious whether any differences are due to something systematic, or just mostly noise.

```{r 2b-se1sp1}
df_tested <- test_cross_sectional(df, theta = theta_start)
df_x1 <- filter(df_tested, x == 1)
df_x0 <- filter(df_tested, x == 0)

plt_data_under <- rbind(binom.confint(sum(df_x1$diagnose), dim(df_x1)[1], method = "asymptotic"), 
      binom.confint(sum(df_x0$diagnose), dim(df_x0)[1], method = "asymptotic"),
      binom.confint(sum(df_x1$disease), dim(df_x1)[1], method = "asymptotic"),
      binom.confint(sum(df_x0$disease), dim(df_x0)[1], method = "asymptotic")) %>%
  rename(diagnosed = x, Incidence = mean) %>%
  mutate(x = as.factor(c(1, 0, 1, 0)),
        status = c("Observed", "Observed", "Actual", "Actual")) 

incidence_ratio <- plt_data_under[1, 4]/plt_data_under[2, 4]
grob <- grobTree(textGrob(paste("Observed incidence ratio:", round(incidence_ratio, 1)),
                          x=0.1,  y=0.9, hjust=0,
  gp=gpar(col="red", fontsize=13, fontface="italic")))

plt_data_under[3:4,5:6] <- NA

plt_data_over <- plt_data_under

plt_data_over[1:2, 4] <- df_tested %>%
  group_by(x) %>%
  mutate(TP = diagnosed & disease) %>%
  summarize(Incidence = mean(TP)) %>%
  arrange(desc(x)) %>%
  pull(Incidence)

plt_data_under[3:4, 4] <- 0

sen_1_spe_1 <- ggplot(plt_data_under, aes(x = status, y = Incidence, fill = x, group = x, alpha = status)) +
  geom_col(position = position_dodge(width = 1), fill = controls_color) +
  geom_col(data = plt_data_over, aes(x = status, y = Incidence, fill = x, group = x, alpha = status), position = position_dodge(width = 1)) +
  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.25, position = position_dodge(width = 1)) +
  labs(title = "Sensitivity = 1, Specificity = 1") +
  xlab("")+
  annotation_custom(grob) +
  scale_alpha_manual(values = c(0.5, 1), guide = "none") + 
  scale_fill_brewer(palette = "Set1", guide = "none") +
  ylim(c(0,0.175))
```

```{r 2b-se1sp0.7}
df_tested <- test_cross_sectional(df, theta = theta_start, sensitivity = 1, specificity = 0.7)
df_x1 <- filter(df_tested, x == 1)
df_x0 <- filter(df_tested, x == 0)

plt_data_under <- rbind(binom.confint(sum(df_x1$diagnose), dim(df_x1)[1], method = "asymptotic"), 
      binom.confint(sum(df_x0$diagnose), dim(df_x0)[1], method = "asymptotic"),
      binom.confint(sum(df_x1$disease), dim(df_x1)[1], method = "asymptotic"),
      binom.confint(sum(df_x0$disease), dim(df_x0)[1], method = "asymptotic")) %>%
  rename(diagnosed = x, Incidence = mean) %>%
  mutate(x = as.factor(c(1, 0, 1, 0)),
        status = c("Observed", "Observed", "Actual", "Actual")) 

incidence_ratio <- plt_data_under[1, 4]/plt_data_under[2, 4]
grob <- grobTree(textGrob(paste("Observed incidence ratio:", round(incidence_ratio, 1)),
                          x=0.1,  y=0.9, hjust=0,
  gp=gpar(col="red", fontsize=13, fontface="italic")))

plt_data_under[3:4,5:6] <- NA

plt_data_over <- plt_data_under

plt_data_over[1:2, 4] <- df_tested %>%
  group_by(x) %>%
  mutate(TP = diagnosed & disease) %>%
  summarize(Incidence = mean(TP)) %>%
  arrange(desc(x)) %>%
  pull(Incidence)

plt_data_under[3:4, 4] <- 0

sen_1_spe_07 <- ggplot(plt_data_under, aes(x = status, y = Incidence, fill = x, group = x, alpha = status)) +
  geom_col(position = position_dodge(width = 1), fill = controls_color) +
  geom_col(data = plt_data_over, aes(x = status, y = Incidence, fill = x, group = x, alpha = status), position = position_dodge(width = 1)) +
  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.25, position = position_dodge(width = 1)) +
  labs(title = "Sensitivity = 1, Specificity = 0.7") +
  xlab("")+
  annotation_custom(grob) +
  scale_alpha_manual(values = c(0.5, 1), guide = "none") + 
  scale_fill_brewer(palette = "Set1", guide = "none") +
  ylim(c(0,0.175))
```

```{r 2b-se0.7sp1}
df_tested <- test_cross_sectional(df, theta = theta_start, sensitivity = 0.7, specificity = 1)
df_x1 <- filter(df_tested, x == 1)
df_x0 <- filter(df_tested, x == 0)

plt_data_under <- rbind(binom.confint(sum(df_x1$diagnose), dim(df_x1)[1], method = "asymptotic"), 
      binom.confint(sum(df_x0$diagnose), dim(df_x0)[1], method = "asymptotic"),
      binom.confint(sum(df_x1$disease), dim(df_x1)[1], method = "asymptotic"),
      binom.confint(sum(df_x0$disease), dim(df_x0)[1], method = "asymptotic")) %>%
  rename(diagnosed = x, Incidence = mean) %>%
  mutate(x = as.factor(c(1, 0, 1, 0)),
        status = c("Observed", "Observed", "Actual", "Actual")) 

incidence_ratio <- plt_data_under[1, 4]/plt_data_under[2, 4]
grob <- grobTree(textGrob(paste("Observed incidence ratio:", round(incidence_ratio, 1)),
                          x=0.1,  y=0.9, hjust=0,
  gp=gpar(col="red", fontsize=13, fontface="italic")))

plt_data_under[3:4,5:6] <- NA

plt_data_over <- plt_data_under

plt_data_over[1:2, 4] <- df_tested %>%
  group_by(x) %>%
  mutate(TP = diagnosed & disease) %>%
  summarize(Incidence = mean(TP)) %>%
  arrange(desc(x)) %>%
  pull(Incidence)

plt_data_under[3:4, 4] <- 0

sen_07_spe_1 <- ggplot(plt_data_under, aes(x = status, y = Incidence, fill = x, group = x, alpha = status)) +
  geom_col(position = position_dodge(width = 1), fill = controls_color) +
  geom_col(data = plt_data_over, aes(x = status, y = Incidence, fill = x, group = x, alpha = status), position = position_dodge(width = 1)) +
  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.25, position = position_dodge(width = 1)) +
  labs(title = "Sensitivity = 0.7, Specificity = 1") +
  xlab("")+
  annotation_custom(grob) +
  scale_alpha_manual(values = c(0.5, 1), guide = "none") + 
  scale_fill_brewer(palette = "Set1", guide = "none") +
  ylim(c(0,0.175))
```

```{r 2b-se0.7sp0.7}
df_tested <- test_cross_sectional(df, theta = theta_start, sensitivity = 0.7, specificity = 0.7)
df_x1 <- filter(df_tested, x == 1)
df_x0 <- filter(df_tested, x == 0)

plt_data_under <- rbind(binom.confint(sum(df_x1$diagnose), dim(df_x1)[1], method = "asymptotic"), 
      binom.confint(sum(df_x0$diagnose), dim(df_x0)[1], method = "asymptotic"),
      binom.confint(sum(df_x1$disease), dim(df_x1)[1], method = "asymptotic"),
      binom.confint(sum(df_x0$disease), dim(df_x0)[1], method = "asymptotic")) %>%
  rename(diagnosed = x, Incidence = mean) %>%
  mutate(x = as.factor(c(1, 0, 1, 0)),
        status = c("Observed", "Observed", "Actual", "Actual")) 

incidence_ratio <- plt_data_under[1, 4]/plt_data_under[2, 4]
grob <- grobTree(textGrob(paste("Observed incidence ratio:", round(incidence_ratio, 1)),
                          x=0.1,  y=0.9, hjust=0,
  gp=gpar(col="red", fontsize=13, fontface="italic")))

plt_data_under[3:4,5:6] <- NA

plt_data_over <- plt_data_under

plt_data_over[1:2, 4] <- df_tested %>%
  group_by(x) %>%
  mutate(TP = diagnosed & disease) %>%
  summarize(Incidence = mean(TP)) %>%
  arrange(desc(x)) %>%
  pull(Incidence)

plt_data_under[3:4, 4] <- 0

sen_07_spe_07 <- ggplot(plt_data_under, aes(x = status, y = Incidence, fill = x, group = x, alpha = status)) +
  geom_col(position = position_dodge(width = 1), fill = controls_color) +
  geom_col(data = plt_data_over, aes(x = status, y = Incidence, fill = x, group = x, alpha = status), position = position_dodge(width = 1)) +
  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.25, position = position_dodge(width = 1)) +
  labs(title = "Sensitivity = 0.7, Specificity = 0.7") +
  xlab("")+
  annotation_custom(grob) +
  scale_alpha_manual(values = c(0.5, 1), guide = "none") + 
  scale_fill_brewer(palette = "Set1", guide = "none") +
  ylim(c(0,0.175))
```

```{r fig.height = 6, fig.width=8}
ggarrange(sen_1_spe_1, sen_1_spe_07, sen_07_spe_1, sen_07_spe_07, ncol = 2, nrow = 2)
```


Finally, 1000 simulations of the same results.

```{r}
run_case2B <- function(se = 1, sp = 1){
  start_df <- generate_cs_beta(prevalence = c(0.075, 0.15), n = N)

  good_model <- glm(disease ~ representativeness + x, data = start_df, family = binomial())

  theta_start <- coef(good_model)
  
  df <- generate_cs_beta(prevalence = c(0.075, 0.15), n = N)
  
  df_tested <- test_cross_sectional(df, theta = theta_start,
                                    sensitivity = se, specificity = sp)
  
  df_tested %>% group_by(x) %>%
      mutate(x = ifelse(x, "X1", "X0")) %>%
      summarize(percent_cases_diagnosed = sum(diagnosed & disease)/sum(disease), est_incidence = sum(diagnosed)/n(), .groups = "drop") %>%
      pivot_wider(names_from = x, values_from = c(percent_cases_diagnosed, est_incidence)) %>%
      mutate(est_relative_incidence = est_incidence_X1/est_incidence_X0) 
}
```

```{r}
# Run small simulation study
result_2B_se1_sp1 <- do.call("rbind", replicate(n = 1000, run_case2B(se = 1, sp = 1), simplify = FALSE))
result_2B_se1_sp07 <- do.call("rbind", replicate(n = 1000, run_case2B(se = 1, sp = 0.7), simplify = FALSE))
result_2B_se07_sp1 <- do.call("rbind", replicate(n = 1000, run_case2B(se = 0.7, sp = 1), simplify = FALSE))
result_2B_se07_sp07 <- do.call("rbind", replicate(n = 1000, run_case2B(se = 0.7, sp = 0.7), simplify = FALSE))
```
```{r}
means2b_se1_sp1 <- result_2B_se1_sp1 %>% summarize_all(mean)
means2b_se1_sp07 <- result_2B_se1_sp07 %>% summarize_all(mean)
means2b_se07_sp1 <- result_2B_se07_sp1 %>% summarize_all(mean)
means2b_se07_sp07 <- result_2B_se07_sp07 %>% summarize_all(mean)

rbind(means2b_se1_sp1, means2b_se1_sp07, means2b_se07_sp1, means2b_se07_sp07) %>%
  `colnames<-`(c("% cases diagnosed (X = 0)", "% cases diagnosed (X = 1)", "est. incidence (X = 0)", "est. incidence (X = 1)", "est. relative incidence")) %>%
  mutate(scenario = c("Perfect test", "Poor specificity", "Poor sensitivity", "Poor sensitivity and specificity")) %>%
  kable(digits = 3)
```

```{r}
sd2b_se1_sp1 <- result_2B_se1_sp1 %>% summarize_all(sd)
sd2b_se1_sp07 <- result_2B_se1_sp07 %>% summarize_all(sd)
sd2b_se07_sp1 <- result_2B_se07_sp1 %>% summarize_all(sd)
sd2b_se07_sp07 <- result_2B_se07_sp07 %>% summarize_all(sd)

rbind(sd2b_se1_sp1, sd2b_se1_sp07, sd2b_se07_sp1, sd2b_se07_sp07) %>%
  `colnames<-`(c("SD % cases diagnosed (X = 0)", "SD % cases diagnosed (X = 1)", "SD est. incidence (X = 0)", "SD est. incidence (X = 1)", "SD est. relative incidence")) %>%
  mutate(scenario = c("Perfect test", "Poor specificity", "Poor sensitivity", "Poor sensitivity and specificity")) %>%
  kable(digits = 3)
```

This is surprising!  It seems the worse tests actually *decrease* the error in estimation for Case 2B.  But why?  Does this stem from the fact that the testing rates are roughly proportional to true disease risk?


### The distribution of representativeness

Unsurprisingly, false-positive individuals tend to fall lower on the distribution of representativeness than the true-positive individuals.  In other words, they "fatten" the left tail of the observed distribution of representativeness.  It's hard to tell if this effect is more pronounced for either group.

```{r fig.height=3, fig.width=8}
x.labs = c("FALSE" = "X = 0", "TRUE" = "X = 1")

diseased <- df_tested %>% filter(disease == TRUE) %>%
  mutate(group = "Individuals with Disease", alpha = 0.7, status = x)

diagnosed <- df_tested %>% filter(diagnosed == TRUE) %>%
  mutate(group = "Individuals Diagnosed", alpha = 1) %>%
  mutate(status = as.factor(ifelse(!disease, 2, x)))

b <- ggplot(data = rbind(diseased, diagnosed), aes(x = representativeness, fill = status, group = status)) +
  geom_histogram(data = diseased, alpha = 0.5, aes(x = representativeness, fill = status, group = status)) +
  geom_histogram(data = diagnosed, aes(x = representativeness, fill = status, group = status)) +
  labs(title = "Distribution of representativeness", x = "Representativeness", y = "Number of individuals") +
  scale_fill_manual(values = c(x0_color, x1_color, controls_color, x0_color, x1_color), drop = F) +
  facet_wrap(~ x, labeller = labeller(x = x.labs)) +
  theme(strip.text.x = element_text(size = 12, face = "bold"), panel.spacing = unit(1, "lines"))

ggarrange(a, b, ncol = 2, widths =c(2,3), legend = F, labels = "AUTO")
```

As before, the distribution of false negatives appears to mirror the distribution of true positives.

```{r fig.height=3, fig.width=8}
x.labs = c("FALSE" = "X = 0", "TRUE" = "X = 1")

diseased <- df_tested %>% filter(disease == TRUE) %>%
  mutate(group = "Individuals with Disease", alpha = 0.7, status = x)

diagnosed <- df_tested %>% filter(diagnosed == TRUE) %>%
  mutate(group = "Individuals Diagnosed", alpha = 1) %>%
  mutate(status = as.factor(ifelse(!disease, 2, x)))

b <- ggplot(data = rbind(diseased, diagnosed), aes(x = representativeness, fill = status, group = status)) +
  geom_histogram(data = diseased, alpha = 0.5, aes(x = representativeness, fill = status, group = status)) +
  geom_histogram(data = diagnosed, aes(x = representativeness, fill = status, group = status)) +
  geom_histogram(data = filter(diseased, tested & !diagnosed), fill = "black") +
  labs(title = "Distribution of representativeness", x = "Representativeness", y = "Number of individuals") +
  scale_fill_manual(values = c(x0_color, x1_color, controls_color, x0_color, x1_color), drop = F) +
  facet_wrap(~ x, labeller = labeller(x = x.labs)) +
  theme(strip.text.x = element_text(size = 12, face = "bold"), panel.spacing = unit(1, "lines"))

ggarrange(a, b, ncol = 2, widths =c(2,3), legend = F, labels = "AUTO")
```

## Case 2C: True risk factor, but overestimated impact

I made up this case in the hopes of better understanding the results from Case 2b. Here, $X$ is a risk factor (as in Case 2B), but the association between $X$ and disease risk is overemphasized in the diagnostic process (as in Case 2B). Specifically, here we'll use the disease model of Case 2B but the biased clinical diagnostic process of Case 2A.

```{r}
run_case2C <- function(se = 1, sp = 1){
  df <- generate_cs_beta(prevalence = c(0.075, 0.15), n = N)
  
  df_tested <- test_cross_sectional(df, theta = c(-13, 20, 3),
                                    sensitivity = se, specificity = sp)
  
  df_tested %>% group_by(x) %>%
      mutate(x = ifelse(x, "X1", "X0")) %>%
      summarize(percent_cases_diagnosed = sum(diagnosed & disease)/sum(disease), est_incidence = sum(diagnosed)/n(), .groups = "drop") %>%
      pivot_wider(names_from = x, values_from = c(percent_cases_diagnosed, est_incidence)) %>%
      mutate(est_relative_incidence = est_incidence_X1/est_incidence_X0) 
}
```

```{r}
# Run small simulation study
result_2C_se1_sp1 <- do.call("rbind", replicate(n = 1000, run_case2C(se = 1, sp = 1), simplify = FALSE))
result_2C_se1_sp07 <- do.call("rbind", replicate(n = 1000, run_case2C(se = 1, sp = 0.7), simplify = FALSE))
result_2C_se07_sp1 <- do.call("rbind", replicate(n = 1000, run_case2C(se = 0.7, sp = 1), simplify = FALSE))
result_2C_se07_sp07 <- do.call("rbind", replicate(n = 1000, run_case2C(se = 0.7, sp = 0.7), simplify = FALSE))
```
```{r}
means2C_se1_sp1 <- result_2C_se1_sp1 %>% summarize_all(mean)
means2C_se1_sp07 <- result_2C_se1_sp07 %>% summarize_all(mean)
means2C_se07_sp1 <- result_2C_se07_sp1 %>% summarize_all(mean)
means2C_se07_sp07 <- result_2C_se07_sp07 %>% summarize_all(mean)

rbind(means2C_se1_sp1, means2C_se1_sp07, means2C_se07_sp1, means2C_se07_sp07) %>%
  `colnames<-`(c("% cases diagnosed (X = 0)", "% cases diagnosed (X = 1)", "est. incidence (X = 0)", "est. incidence (X = 1)", "est. relative incidence")) %>%
  mutate(scenario = c("Perfect test", "Poor specificity", "Poor sensitivity", "Poor sensitivity and specificity")) %>%
  kable(digits = 3)
```

```{r}
sd2C_se1_sp1 <- result_2C_se1_sp1 %>% summarize_all(sd)
sd2C_se1_sp07 <- result_2C_se1_sp07 %>% summarize_all(sd)
sd2C_se07_sp1 <- result_2C_se07_sp1 %>% summarize_all(sd)
sd2C_se07_sp07 <- result_2C_se07_sp07 %>% summarize_all(sd)

rbind(sd2C_se1_sp1, sd2C_se1_sp07, sd2C_se07_sp1, sd2C_se07_sp07) %>%
  `colnames<-`(c("SD % cases diagnosed (X = 0)", "SD % cases diagnosed (X = 1)", "SD est. incidence (X = 0)", "SD est. incidence (X = 1)", "SD est. relative incidence")) %>%
  mutate(scenario = c("Perfect test", "Poor specificity", "Poor sensitivity", "Poor sensitivity and specificity")) %>%
  kable(digits = 3)
```
